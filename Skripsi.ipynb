{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QueeneDelmarva/Skripsi/blob/main/Skripsi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Skripsi Code**"
      ],
      "metadata": {
        "id": "_SUlo9Ee057P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "M02ItnbY2rsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "zLLwah4y2tr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Radix Trie"
      ],
      "metadata": {
        "id": "5lkGFQGI7-aT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nodes"
      ],
      "metadata": {
        "id": "f94wFEi5ibXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Radix Trie: Connecting to GSheets"
      ],
      "metadata": {
        "id": "6bmejAAK7-8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Fuction"
      ],
      "metadata": {
        "id": "xrPzpwaX23zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "import string\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from oauth2client.service_account import ServiceAccountCredentials"
      ],
      "metadata": {
        "id": "kz6TM0g0kPWl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_content(content):\n",
        "    content = content.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "    tokens = content.split()\n",
        "    tokens = [token for token in tokens if token != \"noted\"]\n",
        "    return ''.join(tokens)"
      ],
      "metadata": {
        "id": "wKHuBar5kRSc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmailMetadata:\n",
        "    def __init__(self, to, from_, subject, content):\n",
        "        self.to = to\n",
        "        self.from_ = from_\n",
        "        self.subject = subject\n",
        "        self.content = content"
      ],
      "metadata": {
        "id": "o_39k8AXkTpe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixTrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_end_of_word = False\n",
        "        self.email_metadata = []  # List to store email metadata associated with the word/phrase\n",
        "\n",
        "    def insert(self, word, email_metadata):\n",
        "        node = self\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                node.children[char] = RadixTrieNode()\n",
        "            node = node.children[char]\n",
        "        node.is_end_of_word = True\n",
        "        node.email_metadata.append(email_metadata)\n",
        "\n",
        "    def get_email_preview(self, word):\n",
        "      node = self.root\n",
        "      for char in word:\n",
        "        if char not in node.children:\n",
        "          return None\n",
        "        node = node.children[char]\n",
        "\n",
        "        email_metadata = node.get_email_metadata()  # Retrieve the email metadata associated with the word\n",
        "        if email_metadata:\n",
        "          return email_metadata\n",
        "        return None\n",
        "\n",
        "    def get_email_metadata(self):\n",
        "        return self.email_metadata"
      ],
      "metadata": {
        "id": "FZIZpfZskYpJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixTrie:\n",
        "    def __init__(self):\n",
        "        self.root = RadixTrieNode()\n",
        "\n",
        "    def load_wordlist_from_gsheet(self, gsheet_key, sheet_name=\"wordlist\"):\n",
        "        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "        creds = ServiceAccountCredentials.from_json_keyfile_name('/content/skripsi-394804-a98ea9715aa4.json', scope)\n",
        "        client = gspread.authorize(creds)\n",
        "\n",
        "        worksheet = client.open_by_key(gsheet_key).worksheet('wordlist')\n",
        "        email_data_list = worksheet.get_all_records()  # Fetch all rows as a list of dictionaries\n",
        "\n",
        "        for email_data in email_data_list:\n",
        "            # Preprocess the content before inserting it into the trie\n",
        "            content = self._preprocess_word(email_data['Content'])\n",
        "\n",
        "            if content:\n",
        "              # Extract content into list of word\n",
        "              words = content.split()\n",
        "\n",
        "              for word in words:\n",
        "                self.insert(word, email_data)\n",
        "\n",
        "    def _preprocess_word(self, word):\n",
        "    # Convert the word to lowercase\n",
        "      word = word.lower()\n",
        "\n",
        "    # Remove common greetings and noise words\n",
        "      greetings = [\"hi\", \"hello\", \"dear\", \"regards\", \"thanks\", \"thank you\", \"best regards\"]\n",
        "      if word in greetings:\n",
        "        return None\n",
        "\n",
        "    # Check for repeated information (e.g., \"Re: Re: Subject\")\n",
        "      if word.startswith(\"re:\"):\n",
        "        return None\n",
        "\n",
        "    # Check for null values and very short words\n",
        "    # if not word or len(word) < 3:\n",
        "    #     return None\n",
        "\n",
        "      return word  # Return the processed word only\n",
        "\n",
        "\n",
        "    def insert(self, word, email_metadata):\n",
        "        processed_word = self._preprocess_word(word)\n",
        "        if processed_word is None:\n",
        "            return\n",
        "\n",
        "        node = self.root\n",
        "        for char in processed_word:\n",
        "            if char not in node.children:\n",
        "                node.children[char] = RadixTrieNode()\n",
        "            node = node.children[char]\n",
        "\n",
        "        node.is_end_of_word = True\n",
        "        node.email_metadata = email_metadata\n",
        "\n",
        "    #Ini cuma return none or node\n",
        "    # def search(self, prefix):\n",
        "    #     node = self.root\n",
        "    #     current_match = ''\n",
        "\n",
        "    #     for char in prefix:\n",
        "    #         if char not in node.children:\n",
        "    #             return None  # Return None instead of an empty list\n",
        "\n",
        "    #         current_match += char\n",
        "    #         node = node.children[char]\n",
        "    #         print(current_match)\n",
        "\n",
        "    #     return node  # Return the node containing the last character of the prefix\n",
        "\n",
        "    def collect_words_from_node(self, node, prefix):\n",
        "      words = []\n",
        "      for char, child_node in node.children.items():\n",
        "        # print(\"Im here fucking bitch\");\n",
        "        if child_node.is_end_of_word:\n",
        "            # words.append((prefix + char, child_node.email_metadata))\n",
        "            words.append(prefix + char)\n",
        "        words.extend(self.collect_words_from_node(child_node, prefix + char))\n",
        "\n",
        "      # print(\"Insert find similiar\", prefix)\n",
        "      # print(words)\n",
        "      return words\n",
        "\n",
        "\n",
        "    # Punya Airu, collect all word\n",
        "    def print_all_words(self):\n",
        "      all_words = self.collect_words_from_node(self.root, \"\")\n",
        "\n",
        "      for word in all_words:\n",
        "        print(word)\n",
        "\n",
        "    def search(self, prefix):\n",
        "      node = self.root\n",
        "      current_match = ''\n",
        "      matches = []\n",
        "\n",
        "      for char in prefix:\n",
        "          if char not in node.children:\n",
        "              # If there is no exact match, collect all words starting with current_match\n",
        "              print(\"the last match:\", current_match)\n",
        "              return self.collect_words_from_node(node, current_match)\n",
        "\n",
        "          current_match += char\n",
        "          node = node.children[char]\n",
        "\n",
        "          if node.is_end_of_word:\n",
        "              # Collect the current word if it ends at this node\n",
        "              print(\"End of word\")\n",
        "              matches.append(current_match)\n",
        "\n",
        "      print(\"Return karena sama sampai akhir\")\n",
        "      return matches\n",
        "\n",
        "    def _get_suggested_phrases(self, node, prefix):\n",
        "      phrases = []\n",
        "      if node.is_end_of_word:\n",
        "        phrases.append(prefix)\n",
        "\n",
        "        for char, child_node in node.children.items():\n",
        "          phrases.extend(self._get_suggested_phrases(child_node, prefix + char + \" \"))\n",
        "\n",
        "        return phrases\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def levenshtein_distance(s1, s2):\n",
        "        if len(s1) > len(s2):\n",
        "            s1, s2 = s2, s1\n",
        "\n",
        "        distances = range(len(s1) + 1)\n",
        "        for index2, char2 in enumerate(s2):\n",
        "            new_distances = [index2 + 1]\n",
        "            for index1, char1 in enumerate(s1):\n",
        "                if char1 == char2:\n",
        "                    new_distances.append(distances[index1])\n",
        "                else:\n",
        "                    insert_cost = distances[index1 + 1] + 1\n",
        "                    delete_cost = new_distances[-1] + 1\n",
        "                    replace_cost = distances[index1] + 1\n",
        "                    new_distances.append(min(insert_cost, delete_cost, replace_cost))\n",
        "            distances = new_distances\n",
        "\n",
        "        return distances[-1]\n",
        "\n",
        "    def autocomplete(self, word):\n",
        "        suggestions = self.search(word)\n",
        "\n",
        "        print(\"Inside Autocomplete\")\n",
        "        print(suggestions)\n",
        "\n",
        "        # Negative Cases\n",
        "        if not suggestions:\n",
        "            closest_word = self.get_closest_word(word)\n",
        "            print(f\"Suggestions: {', '.join([closest_word])}\")\n",
        "            user_choice = input(\"Is this the word you are looking for? (Y/N): \").strip().lower()\n",
        "            if user_choice == \"y\":\n",
        "                closest_word_node = self.search(closest_word)\n",
        "                if closest_word_node:\n",
        "                    show_preview = input(\"Do you want to view a snippet preview of the email data? (Y/N): \").strip().lower()\n",
        "                    if show_preview == \"y\":\n",
        "                        email_metadata_list = closest_word_node.email_metadata\n",
        "                        return email_metadata_list  # Return the list of email metadata\n",
        "                return [closest_word]\n",
        "\n",
        "            while True:\n",
        "                new_word = input(\"Enter the correct spelling or 'cancel' to cancel or 'add' to add as a new word: \").strip().lower()\n",
        "                if new_word == \"cancel\":\n",
        "                    print(\"Word not found. Check for misspellings.\")\n",
        "                    return []\n",
        "\n",
        "                suggestions = self.search(new_word)\n",
        "                if suggestions:\n",
        "                    return suggestions\n",
        "\n",
        "                user_choice = input(\"Word not found. Do you want to add it as a new word? (Y/N): \").strip().lower()\n",
        "                if user_choice == \"y\":\n",
        "                    email_metadata = EmailMetadata(to='', from_='', subject='', content=word)\n",
        "                    self.insert(word, email_metadata)\n",
        "                    gsheet_url = 'https://docs.google.com/spreadsheets/d/1RlZ8-XwwEueuCAq4nXGwq3ZmPDE-_0gP3PsroKeNFGo/edit#gid=2071884403'\n",
        "                    self.save_wordlist_to_gsheet(gsheet_url, new_sheet_name=\"newwords\")  # Save the updated wordlist\n",
        "                    print(\"New word added to the wordlist\")\n",
        "                    return [\"New word added to the wordlist\"]\n",
        "\n",
        "        return suggestions\n",
        "\n",
        "    def print_email_preview(self, email_metadata):\n",
        "        print(\"Email Preview:\")\n",
        "        print(f\"To: {email_metadata.to}\")\n",
        "        print(f\"From: {email_metadata.from_}\")\n",
        "        print(f\"Subject: {email_metadata.subject}\")\n",
        "        print(f\"Content: {email_metadata.content}\")\n",
        "\n",
        "    def get_closest_word(self, word):\n",
        "        min_distance = float('inf')\n",
        "        closest_word = None  # Initialize closest_word to None\n",
        "        for known_word in self._get_all_words(self.root, \"\"):\n",
        "            distance = self.levenshtein_distance(word, known_word)\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                closest_word = known_word\n",
        "\n",
        "        return closest_word  # Return None if no closest word is found\n",
        "\n",
        "    def _get_all_words(self, node, prefix):\n",
        "        words = []\n",
        "        if node.is_end_of_word:\n",
        "            words.append(prefix)\n",
        "\n",
        "        for char, child_node in node.children.items():\n",
        "            words.extend(self._get_all_words(child_node, prefix + char))\n",
        "\n",
        "        return words\n",
        "\n",
        "    def save_wordlist_to_gsheet(self, gsheet_url, new_sheet_name=\"newwords\"):\n",
        "        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "        creds = ServiceAccountCredentials.from_json_keyfile_name('/content/skripsi-394804-a98ea9715aa4.json', scope)\n",
        "        client = gspread.authorize(creds)\n",
        "\n",
        "        # Open the Google Sheets document using the URL\n",
        "        doc = client.open_by_url(gsheet_url)\n",
        "\n",
        "        try:\n",
        "            # Try to access the 'newwords' worksheet directly by title\n",
        "            worksheet = doc.worksheet(new_sheet_name)\n",
        "        except gspread.exceptions.WorksheetNotFound:\n",
        "            # If the worksheet doesn't exist, create it\n",
        "            worksheet = doc.add_worksheet(title=new_sheet_name, rows=1, cols=1)\n",
        "            worksheet.append_row([\"New Words\"])  # Write the header\n",
        "\n",
        "        # Get the new words from the trie\n",
        "        new_words = list(set(self._get_all_words(self.root, \"\")))\n",
        "\n",
        "        # Clear the existing content of the worksheet and write the new words\n",
        "        worksheet.clear()\n",
        "        worksheet.append_row([\"New Words\"])  # Write the header\n",
        "        for word in new_words:\n",
        "            worksheet.append_row([word])\n",
        "\n",
        "    def get_email_preview(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                return None\n",
        "            node = node.children[char]\n",
        "\n",
        "        return node.email_metadata"
      ],
      "metadata": {
        "id": "iFtxfr4bkdNa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    trie = RadixTrie()\n",
        "\n",
        "    # Load the wordlist from Google Sheets when starting the program\n",
        "    gsheet_key = '1RlZ8-XwwEueuCAq4nXGwq3ZmPDE-_0gP3PsroKeNFGo'\n",
        "    trie.load_wordlist_from_gsheet(gsheet_key)\n",
        "    trie.print_all_words()\n",
        "\n",
        "    # # while True:\n",
        "\n",
        "    # count = 0\n",
        "    # while count < 1:\n",
        "    #     count += 1\n",
        "\n",
        "    #     user_input = input(\"Enter a word: \").strip().lower()\n",
        "\n",
        "    #     if user_input == \"exit\":\n",
        "    #         break\n",
        "\n",
        "    #     suggestions = trie.autocomplete(user_input)\n",
        "        # if suggestions:\n",
        "        #   print(\"Gua disini anjing\")\n",
        "        #   print(suggestions)\n",
        "          # print(type(suggestions))\n",
        "          # print(\"Gua diatas anjing\")\n",
        "\n",
        "\n",
        "    #       if isinstance(suggestions, EmailMetadata):  # Check if the suggestions are of type EmailMetadata\n",
        "    #           for email_metadata in suggestions:\n",
        "    #             trie.print_email_preview(email_metadata)\n",
        "    #       else:\n",
        "    #           print(f\"Suggestions: {', '.join(suggestions)}\")\n",
        "    #     else:\n",
        "    #         print(\"Word not found.\")\n",
        "    #         print(\"1. Correct the spelling\")\n",
        "    #         print(\"2. Add this word as a new word\")\n",
        "    #         choice = input(\"Enter your choice (1/2): \").strip()\n",
        "\n",
        "    #         if choice == \"1\":\n",
        "    #           while True:\n",
        "    #             new_word = input(\"Enter the correct spelling or 'cancel' to cancel: \").strip().lower()\n",
        "    #             if new_word == \"cancel\":\n",
        "    #               break\n",
        "\n",
        "    #             suggestions = trie.autocomplete(new_word)\n",
        "    #             if suggestions and suggestions[0] != new_word:\n",
        "    #               print(f\"Suggestions: {', '.join(suggestions)}\")\n",
        "    #               break\n",
        "    #             else:\n",
        "    #               print(\"Word not found.\")\n",
        "\n",
        "    #         elif choice == \"2\":\n",
        "    #           email_metadata = EmailMetadata(to='', from_='', subject='', content=user_input)\n",
        "    #           trie.insert(user_input, email_metadata)\n",
        "    #           print(\"New word added to the wordlist\")\n",
        "\n",
        "    # # Save new words to a different sheet in Google Sheets\n",
        "    # trie.save_wordlist_to_gsheet(gsheet_key, new_sheet_name=\"New Words\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiLDLwhirCJc",
        "outputId": "4056aa83-5396-4b11-f009-55c923e29be5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noted\n",
            "a\n",
            "and\n",
            "arrange\n",
            "as\n",
            "airport\n",
            "aviation\n",
            "aerospace\n",
            "confirmed\n",
            "comments:\n",
            "changi\n",
            "centre21\n",
            "crew\n",
            "thanks.\n",
            "transportation\n",
            "time:\n",
            "tumboimbella\n",
            "tue\n",
            "tba\n",
            "please\n",
            "passenger:\n",
            "pickup\n",
            "ground\n",
            "follows:\n",
            "feb\n",
            "few\n",
            "fa\n",
            "request\n",
            "road\n",
            "rmark:\n",
            "date:\n",
            "drop-off\n",
            "wed\n",
            "with\n",
            "01\n",
            "01,\n",
            "0840lt\n",
            "03\n",
            "2023\n",
            "qg-552\n",
            "quwense\n",
            "eta\n",
            "location:\n",
            "limousine\n",
            "luggage\n",
            "seletar\n",
            "singapore\n",
            "sbac\n",
            "business\n",
            "1797405,\n",
            "1930lt\n",
            "vehicles:\n",
            "jhasletha\n",
            "jan\n",
            "mpv\n",
            "has\n",
            "her.\n",
            "hotel\n",
            "31\n",
            "31jan\n",
            "/\n",
            "-\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}